{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/az1fr3/AudioTools/blob/main/StableAudiOpen_ByAzufr3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSEcmH_1WCUi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#\n",
        "# _____ _        _     _         ___            _ _         _\n",
        "#/  ___| |      | |   | |       / _ \\          | (_)       | |          _\n",
        "#\\ `--.| |_ __ _| |__ | | ___  / /_\\ \\_   _  __| |_  ___   | |__  _   _(_)\n",
        "# `--. \\ __/ _` | '_ \\| |/ _ \\ |  _  | | | |/ _` | |/ _ \\  | '_ \\| | | |\n",
        "#/\\__/ / || (_| | |_) | |  __/ | | | | |_| | (_| | | (_) | | |_) | |_| |_\n",
        "#\\____/ \\__\\__,_|_.__/|_|\\___| \\_| |_/\\__,_|\\__,_|_|\\___/  |_.__/ \\__, (_)\n",
        "#                                                                 __/ |\n",
        "#                                                                |___/\n",
        "\n",
        "#  █████╗ ███████╗ ██╗███████╗██████╗ ██████╗\n",
        "# ██╔═██╗╚══███╔╝███║██╔════╝██╔══██╗╚════██╗\n",
        "# ███████║  ███╔╝ ╚██║█████╗  ██████╔╝ █████╔╝\n",
        "# ██╔══██║ ███╔╝   ██║██╔══╝  ██╔══██╗ ╚═══██╗\n",
        "# ██║  ██║███████╗ ██║██║     ██║  ██║██████╔╝\n",
        "# ╚═╝  ╚═╝╚══════╝ ╚═╝╚═╝     ╚═╝  ╚═╝╚═════╝\n",
        "# ▒▒   ▓▒█░░▒▒ ▓░▒░▒ ▒ ░    ░ ▒▓ ░▒▓░\n",
        "#   ▒   ▒▒ ░░░▒ ▒ ░ ▒ ░        ░▒ ░ ▒░\n",
        "#   ░   ▒   ░ ░ ░ ░ ░ ░ ░      ░░   ░\n",
        "#       ░  ░  ░ ░               ░\n",
        "#           ░\n",
        "#\n",
        "# Linktree : https://linktr.ee/az1fr3\n",
        "#\n",
        "# Chequear el funcionamiento de NVIDIA, si te arroja algún error, en el menú ve a entorno de ejecución y activa la gpu Nvidia Tesla T4\n",
        "#\n",
        "# Para información sobre audigen visita su Github: https://github.com/facebookresearch/audiocraft\n",
        "#\n",
        "# Desactia los gatos para la Música opcional para esperar las descargas ^^ ░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░#|\n",
        "#\n",
        "#!wget -q \"https://ia601209.us.archive.org/20/items/Chiptune_Songs_Archive/McFiredrill%20-%20Computer%20Trash/04%20-%20Vitamin%20D.mp3\" -O keygenmusic.mp3\n",
        "#\n",
        "#from IPython.display import Audio; display(Audio(\"keygenmusic.mp3\", autoplay=True))\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "#Instalar las dependencias\n",
        "!pip install protobuf==4.21.12\n",
        "!pip install --upgrade numpy protobuf\n",
        "!pip install stable-audio-tools\n",
        "\n",
        "\n",
        "# Puedes puasar la musica de espera en el reproductor que está justo aqui abajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFAZ9VFzsK_Z"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from einops import rearrange\n",
        "from stable_audio_tools import get_pretrained_model\n",
        "from stable_audio_tools.inference.generation import generate_diffusion_cond\n",
        "\n",
        "#Este comando nos permite correr la app en la cpu sin necesidad de tener una GPU cuda,\n",
        "#pero por defecto viene activa el poder de la GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--wHKqyKsZyG"
      },
      "outputs": [],
      "source": [
        "# Descarga el modelo:\n",
        "model, model_config = get_pretrained_model(\"audo/stable-audio-open-1.0\") # Gracias a @Camenduru por el modelo de libre acceso!\n",
        "sample_rate = model_config[\"sample_rate\"]\n",
        "sample_size = model_config[\"sample_size\"]\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq_RZR2zWEEA"
      },
      "outputs": [],
      "source": [
        "# Setup General\n",
        "conditioning = [{\n",
        "    \"prompt\": \" 120bpm techno electronic analoge vintage drum machine 32bit\", #Escribe entre las comillas tu comando para generar\n",
        "    \"seconds_start\": 0,\n",
        "    \"seconds_total\": 35 # Este numero representa la cantidad de segundos totales de tu archivo\n",
        "}]\n",
        "\n",
        "# Genera audio stereo\n",
        "output = generate_diffusion_cond(\n",
        "    model,\n",
        "    steps=100,\n",
        "    cfg_scale=7,\n",
        "    conditioning=conditioning,\n",
        "    sample_size=sample_size,\n",
        "    sigma_min=0.3,\n",
        "    sigma_max=500,\n",
        "    sampler_type=\"dpmpp-3m-sde\",\n",
        "    device=device\n",
        ")\n",
        "# Rearrange audio batch to a single sequence\n",
        "output = rearrange(output, \"b d n -> d (b n)\")\n",
        "\n",
        "# Peak normalize, clip, convert to int16, and save to file\n",
        "output = output.to(torch.float32).div(torch.max(torch.abs(output))).clamp(-1, 1).mul(32767).to(torch.int16).cpu()\n",
        "torchaudio.save(\"output.wav\", output, sample_rate)\n",
        "\n",
        "from IPython.display import Audio, display\n",
        "display(Audio(\"/content/output.wav\", autoplay=True))\n",
        "\n",
        "#Si te gustó este notebook considera dejarme una propina en Kofi: https://ko-fi.com/az1fr3\n",
        "#o considera sumarte a mi Patreon y tener acceso a las herramientas mejoradas de AI: https://www.patreon.com/Az1fr3"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOmWAa8ywykIPIXFR8pLJDY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
